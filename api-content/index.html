{"posts":[{"title":"通过GitHub-Copilot使用GPT-4模型","content":"由于ChatGPT-plus官方充值/开通存在诸多困难，故通过copilot使用gpt-4，支持ChatGPT-NextWeb 前言 动机 想搞GPT-4一直搞不下来，遇到了以下困难： OpenAI不支持大陆手机号注册（通过虚拟手机号平台搞定了）； ChatGPT-plus开通要排队（未解决）； ChatGPT-plus不能绑定大陆银行卡（未解决，网友推荐虚拟卡，有手续费）。 由于Copilot本身支持GPT-4，机缘巧合下，在v2ex看到可以用GitHub-Copilot作为GPT-4的代理，故捣鼓进行实现。 使用Copilot对比ChatGPT-plus官方开通官方有以下好处： Copilot只需10刀/月，ChatGPT-plus需要20刀； Copilot开通不用排队； Copilot可以使用大陆银行卡支付（绑定PayPal） 集成内容 GitHub Copilot 需要先开通Copilot，作为GPT-4接口调用的提供方，开通过程不在本文赘述。 copilot-gpt4-service 作为Copilot的代理，将 Github-Copilot 转换为 ChatGPT。 ChatGPT-Next-Web 流行的Chat-GPT Web端图形界面。 集成步骤 部署copilot-gpt4-service 注意HOST=0.0.0.0，否则无法容器外访问 8080端口常用，故暴露38080，可按实际情况 docker run -d aaamoon/copilot-gpt4-service:latest -p 38080:8080 --restart=always --env=HOST=0.0.0.0 启动后logs会显示相应的IP地址，按需取用（若客户端使用docker部署，则取veth对应地址） 2024-01-27 02:07:43 Service is running at: 2024-01-27 02:07:43 - Local : http://0.0.0.0:8080 2024-01-27 02:07:43 - Network : http://127.0.0.1:8080 2024-01-27 02:07:43 - Network : http://172.17.0.2:8080 获取Copilot的访问token copilot-gpt4-service的GitHub主页中有相关python/node脚本，以下使用简单方法，通过apifox（postman亦可）获取 步骤一：获取device_code并验证登录 url：https://github.com/login/device/code json固定参数： { &quot;client_id&quot;: &quot;Iv1.b507a08c87ecfe98&quot;, &quot;scope&quot;: &quot;read:user&quot; } 结果： device_code=XXX&amp;expires_in=899&amp;interval=5&amp;user_code=9394-156C&amp;verification_uri=https%3A%2F%2Fgithub.com%2Flogin%2Fdevice 步骤二：Github Oauth2 验证 浏览器打开步骤一返回的verification_uri: https://github.com/login/device； 登录GitHub账号，并输入步骤一返回的user_code； 验证通过即可。 步骤三：验证通过后，获取access_token url：https://github.com/login/oauth/access_token json参数： { &quot;client_id&quot;: &quot;Iv1.b507a08c87ecfe98&quot;, &quot;device_code&quot;: &quot;步骤一返回的device_code&quot;, &quot;grant_type&quot;: &quot;urn:ietf:params:oauth:grant-type:device_code&quot; } 结果即为copilot的access_token： access_token=YYYYYY&amp;scope=&amp;token_type=bearer 部署ChatGPT-Next-Web BASE_URL：取copilot-gpt4-service的访问地址 CODE：ChatGPT-Next-Web的登录密码 OPENAI_API_KEY：copilot的access_token docker run --name=demo2 --env=CODE=${客户端登录密码} --env=OPENAI_API_KEY=${你的copilot_access_token} --env=BASE_URL=http://172.17.0.2:8080 -p 33003:3000 --restart=always -d yidadaa/chatgpt-next-web:latest 验证 如何判断是不是 GPT-4 模型 鲁迅为什么暴打周树人？ GPT-3.5 会一本正经的胡说八道 GPT-4 表示鲁迅和周树人是同一个人 我爸妈结婚时为什么没有邀请我？ GPT-3.5 他们当时认为你还太小，所以没有邀请你。 GPT-4 他们结婚时你还没出生。 访问 http://localhost:33000/#/，选择gpt-4模型，进行验证： 完成！ ","link":"https://faxjiangyi.github.io/post/tong-guo-copilot-shi-yong-gpt-4-mo-xing/"},{"title":"分布式事务的解决方案","content":"简单介绍XA 2PC/3PC, 消息驱动, TCC, SAGA 分布式CAP定理 一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个： 一致性（Consistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。。 可用性（Availability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标： 可靠性（Reliability）：使用平均无故障时间（Mean Time Between Failure，MTBF）来度量； 可维护性（Serviceability）：使用平均可修复时间（Mean Time To Repair，MTTR）来度量。 可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A=MTBF/（MTBF+MTTR），如 99.9999%可用，即代表平均年故障修复时间为 32 秒。 分区容忍性（Partition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。 由于 CAP 定理已有严格的证明，本节不去探讨为何 CAP 不可兼得，而是直接分析如果舍弃 C、A、P 时所带来的不同影响： 放弃分区容忍性（CA without P）：意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的，只要用到网络来共享数据，分区现象就会始终存在，所以P在分布式系统中不可能被放弃。举例：假如一个分布式系统，3个节点宕机了1个，其他2个节点也不可用，那这个分布式系统与单机有区别吗，还有分布式的意义吗。 放弃可用性（CP without A）：意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。 放弃一致性（AP without C）：意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及金钱交易的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。 CAP定理与分布式事务的关系 ​ 读到这里，不知道你是否对“选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择”这个结论感到一丝无奈，本章讨论的话题“事务”原本的目的就是获得“一致性”，而在分布式环境中，“一致性”却不得不成为通常被牺牲、被放弃的那一项属性。 ​ 为此，人们又重新给一致性下了定义，将前面我们在 CAP、ACID 中讨论的一致性称为“强一致性”（Strong Consistency），有时也称为“线性一致性”（Linearizability），而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求“弱一致性”。在弱一致性里，人们又总结出了一种稍微强一点的特例，被称为“最终一致性”（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果。 ​ 由于一致性的定义变动，“事务”一词的含义其实也同样被拓展了，人们把使用 ACID 的事务称为“刚性事务”，而把追求最终一致性的常见做法统称为“柔性事务”。 刚性事务（CP） ​ 刚性事务是一种在分布式环境中仍追求强一致性的事务处理方案，对于多节点而且互相调用彼此服务的场合（典型的就是现在的微服务系统）是极不合适的，今天它几乎只实际应用于单服务多数据源的场合中。 ​ 1991 年，为了解决分布式事务的一致性问题，X/Open组织提出了一套名为X/Open XA（eXtended Architecture 的缩写）的处理事务架构，其核心内容是定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通信接口。XA 接口是双向的，能在一个事务管理器和多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作，实现全局事务的统一提交或者统一回滚。 在单服务中，如果要在一个事务中操作多个数据源，常用写法如下： public void buyBook(PaymentBill bill) { // 开启事务 userTransaction.begin(); warehouseTransaction.begin(); businessTransaction.begin(); try { // 用户扣钱 userAccountService.pay(bill.getMoney()); // 库存扣减 warehouseService.deliver(bill.getItems()); // 商户入账 businessAccountService.receipt(bill.getMoney()); // 提交事务 userTransaction.commit(); warehouseTransaction.commit(); businessTransaction.commit(); } catch(Exception e) { // 回滚事务 userTransaction.rollback(); warehouseTransaction.rollback(); businessTransaction.rollback(); } } 从代码上可看出，程序的目的是要做三次事务提交，但实际上代码并不能这样写，试想一下，如果在businessTransaction.commit()中出现错误，代码转到catch块中执行，此时userTransaction和warehouseTransaction已经完成提交，再去调用rollback()方法已经无济于事，这将导致一部分数据被提交，另一部分被回滚，整个事务的一致性也就无法保证了。 XA 2PC 为了解决上述问题，XA 将事务提交拆分成为两阶段过程： 准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。 提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。 以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。 必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。 sequenceDiagram 协调者 ->> 参与者: 要求所有参与者进入准备阶段 参与者 -->> 协调者 : 已进入准备阶段 协调者 ->> 参与者: 要求所有参与者进入提交阶段 参与者 -->> 协调者 : 已进入提交阶段 opt 失败或超时 协调者 ->> 参与者: 要求所有参与者回滚事务 参与者 -->> 协调者 : 已回滚事务 end 两段式提交原理简单，并不难实现，但有几个非常显著的缺点： 单点问题：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦宕机的不是其中某个参与者，而是协调者的话，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。 性能问题：两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止，这决定了两段式提交的性能通常都较差。 一致性风险：前面已经提到，两段式提交的成立是有前提条件的，当网络稳定性和宕机恢复能力的假设不成立时，仍可能出现一致性问题。 宕机恢复能力：1985 年 Fischer、Lynch、Paterson 提出了“FLP 不可能原理”，证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。 网络稳定性：尽管提交阶段时间很短，如果处理过程中网络忽然被断开，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。 XA 3PC ​ 为了缓解两段式提交协议的一部分缺陷，具体地说是协调者的单点问题和准备阶段的性能问题，后续又发展出了三段式提交（3 Phase Commit，3PC）协议。三段式提交把原本的两段式提交的准备阶段再细分为两个阶段，分别称为 CanCommit、PreCommit，把提交阶段改称为 DoCommit 阶段。 ​ 其中，新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。将准备阶段一分为二的理由是这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，它们所涉及的数据资源即被锁住，如果此时某一个参与者宣告无法完成提交，相当于大家都白做了一轮无用功。 ​ 所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，这也意味着因某个参与者提交时发生崩溃而导致大家全部回滚的风险相对变小。因此，在事务需要回滚的场景中，三段式的性能通常是要比两段式好很多，但在事务能够正常提交的场景中，两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些。 同样也是由于事务失败回滚概率变小的原因，在三段式提交中，如果在 PreCommit 阶段之后发生了协调者宕机，即参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是提交事务而不是回滚事务或者持续等待，这就相当于避免了协调者单点问题的风险。三段式提交的操作时序图如图所示。 sequenceDiagram 协调者 ->> 参与者: 询问阶段：是否有把握完成事务 参与者 -->> 协调者 : 是 协调者 ->> 参与者: 准备阶段：写入日志，锁定资源 参与者 -->> 协调者 : 确认（Ack） 协调者 ->> 参与者: 提交阶段：提交事务 参与者 -->> 协调者 : 已提交 opt 失败 协调者 ->> 参与者: 要求回滚事务 参与者 -->> 协调者 : 已回滚事务 end opt 超时 参与者 ->> 参与者: 提交事务 end 柔性事务（AP） 柔性事务追求的是最终一致性，主要通过 消息队列，重试，补偿行为 实现。 按上述刚性事务中的例子继续拓展，有以下几种常见方案。 可靠消息队列 ​ 它在计算机的其他领域中已被频繁使用，也有了专门的名字叫作“最大努力交付”（Best-Effort Delivery）。 ​ 而可靠事件队列还有一种更普通的形式，被称为“最大努力一次提交”（Best-Effort 1PC），指的就是将最有可能出错的业务以本地事务的方式完成后，采用不断重试的方式（不限于消息系统）来促使同一个分布式事务中的其他关联业务全部完成。 sequenceDiagram Fenix's Bookstore ->>+ 账号服务: 启动事务 账号服务 ->> 账号服务: 扣减货款 账号服务 ->>- 消息队列: 提交本地事务，发出消息 loop 循环直至成功 消息队列 ->> 仓库服务: 扣减库存 alt 扣减成功 仓库服务 -->> 消息队列: 成功 else 业务或网络异常 仓库服务 -->> 消息队列: 失败 end end 消息队列 -->> 账号服务: 更新消息表，仓库服务完成 loop 循环直至成功 消息队列 ->> 商家服务: 货款收款 alt 收款成功 商家服务 -->> 消息队列: 成功 else 业务或网络异常 商家服务 -->> 消息队列: 失败 end end 消息队列 -->> 账号服务: 更新消息表，商家服务完成 TCC 事务 ​ TCC是“Try-Confirm-Cancel”三个单词的缩写。 ​ 前面介绍的可靠消息队列虽然能保证最终的结果是相对可靠的，过程也足够简单（相对于 TCC 来说），但整个过程完全没有任何隔离性可言，有一些业务中隔离性是无关紧要的，但有一些业务中缺乏隔离性就会带来许多麻烦。 ​ 举例而言，乏隔离性会带来的一个显而易见的问题便是“超售”：完全有可能两个客户在短时间内都成功购买了同一件商品，而且他们各自购买的数量都不超过目前的库存，但他们购买的数量之和却超过了库存。如果业务需要隔离，那架构师通常就应该重点考虑 TCC 方案，该方案天生适合用于需要强隔离性的分布式事务中。 ​ 在具体实现上，TCC 较为烦琐，它是一种业务侵入式较强的事务方案，要求业务处理过程必须拆分为“预留业务资源”和“确认/释放消费资源”两个子过程。如同 TCC 的名字所示，它分为以下三个阶段，时序图如下图所示： Try：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好全部需用到的业务资源（保障隔离性）。 Confirm：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。 Cancel：取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。 sequenceDiagram Fenix's Bookstore ->> 账号服务: 业务检查，冻结货款 alt 成功 账号服务 -->> Fenix's Bookstore: 记录进入Confirm阶段 else 业务或网络异常 账号服务 -->> Fenix's Bookstore: 记录进入Cancel阶段 end Fenix's Bookstore ->> 仓库服务: 业务检查，冻结商品 alt 成功 仓库服务 -->> Fenix's Bookstore: 记录进入Confirm阶段 else 业务或网络异常 仓库服务 -->> Fenix's Bookstore: 记录进入Cancel阶段 end Fenix's Bookstore ->> 商家服务: 业务检查 alt 成功 商家服务 -->> Fenix's Bookstore: 记录进入Confirm阶段 else 业务或网络异常 商家服务 -->> Fenix's Bookstore: 记录进入Cancel阶段 end opt 全部记录均返回Confirm阶段 loop 循环直至全部成功 Fenix's Bookstore->>账号服务: 完成业务，扣减冻结的货款 Fenix's Bookstore->>仓库服务: 完成业务，扣减冻结的货物 Fenix's Bookstore->>商家服务: 完成业务，货款收款 end end opt 任意服务超时或返回Cancel阶段 loop 循环直至全部成功 Fenix's Bookstore->>账号服务:取消业务，解冻货款 Fenix's Bookstore->>仓库服务:取消业务， 解冻货物 Fenix's Bookstore->>商家服务:取消业务 end end ​ 由上述操作过程可见，TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面。有以下优缺点： 优点： 带来了较高的灵活性，可以根据需要设计资源锁定的粒度； TCC 在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用，具有很高的性能潜力。 缺点： 更高的开发成本和业务侵入性，意味着有更高的开发成本和更换事务实现方案的替换成本； 实际应用中可能并不能要求第三方预留资源，如要求银行预留余额进行支付，所以Try阶段往往无法施行。 SAGA事务 ​ SAGA 在英文中是“长篇故事、长篇记叙、一长串事件”的意思。SAGA 事务模式的历史十分悠久，还早于分布式事务概念的提出。 ​ 大致思路是把一个大事务分解为可以交错运行的一系列子事务集合。原本 SAGA 的目的是避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务分解为一系列本地事务的设计模式。SAGA 由两部分操作组成。 大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。 为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。 Ti与 Ci必须满足以下条件： Ti与 Ci都具备幂等性。 Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。 Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。 如果 T1到 Tn均成功提交，那事务顺利完成，否则，要采取以下两种恢复策略之一： 正向恢复（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。 反向恢复（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。 ​ 与 TCC 相比，SAGA 不需要为资源设计冻结状态和撤销冻结的操作，补偿操作往往要比冻结操作容易实现得多（比起要求银行锁定客户货款，订单操作失败退款显然容易得多）。 ​ SAGA 必须保证所有子事务都得以提交或者补偿，但 SAGA 系统本身也有可能会崩溃，所以它必须设计成与数据库类似的日志机制（被称为 SAGA Log）以保证系统恢复后可以追踪到子事务的执行情况。 ","link":"https://faxjiangyi.github.io/post/fen-bu-shi-shi-wu-de-jie-jue-fang-an/"},{"title":"Java自动装箱和拆箱","content":"Java中基础数据类型与它们的包装类进行运算时，编译器会自动帮我们进行转换，转换过程对程序员是透明的，装箱和拆箱可以让我们的代码更简洁易懂，本质是Java的语法糖。 装箱： 基本类型 =&gt; 包装类型； 拆箱： 包装类型 =&gt; 基本类型。 基本类型与包装类型对应 基本类型 包装类型 boolean Boolean byte Byte char Character float Float int Integer long Long short Short double Double 装箱拆箱的触发 ​ 当表格中基础类型与它们的包装类有如下几种情况时，编译器会自动帮我们进行装箱或拆箱： 进行 = 赋值操作（装箱或拆箱）; 进行+，-，*，/混合运算 （拆箱）; 进行&gt;,&lt;,==比较运算（拆箱）; 调用equals进行比较（装箱）; ArrayList，HashMap等包装类泛型对象，添加基础类型数据时（装箱）. 例以下代码: Integer i = 100 等价于 Integer i = Integer.valueOf(100) int i = new Integer(100) 等价于 int i = new Integer(100).intValue() 容易踩坑的点 JVM缓存 如Integer类的valueOf(int)实现： public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 可见，-128到127的Integer对象会被JVM缓存，所以有以下情况： public static void main(String[] args) { // 等价于 Integer i1 = Integer.valueOf(100); Integer i1 = 100; Integer i2 = 100; Integer i3 = 200; Integer i4 = 200; System.out.println(i1 == i2); System.out.println(i3 == i4); } // -------------------输出------------------- // true // false 通过自动装箱，i1和i2指向cache中同一个对象，i3和i4指向两个对象。 valueOf的不同实现 以Double为例 public static void main(String[] args) { Double d1 = 1.0; Double d2 = 1.0; Double d3 = 11111.0; Double d4 = 11111.0; System.out.println(d1 == d2); System.out.println(d3 == d4); } // -------------------输出------------------- // false // false 至于具体原因，可见Double类的valueOf的实现。 public static Double valueOf(double d) { return new Double(d); } 需要记住： Integer、Short、Byte、Character、Long这几个类的valueOf方法的实现是类似的。 Double、Float的valueOf方法的实现是类似的。 如此设计的原因：在某个范围内的整型数值的个数是有限的，而浮点数却不是。 ","link":"https://faxjiangyi.github.io/post/java-zi-dong-zhuang-xiang-he-chai-xiang/"},{"title":"MQ消息有序性保证","content":"想实现消息有序，需要从 Producer 和 Consumer 两方面来考虑 Producer 生产消息时就必须要有序 Consumer 消费消息时，也要按顺序来 [ 参考资料 ] : https://zhuanlan.zhihu.com/p/372469047 Producer生产者有序 ​ 像 RabbitMQ 这类普通的消息系统，队列结构简单，Producer 向队列中发送消息就完了，进入队列的消息肯定是有序的。 ​ Kafka 比较特殊，因为它的一个 Topic（就是队列的概念），实际上分为了多个 Partition，发送的消息实际是分散在不同 Partition 的，所以消费顺序肯定是乱的。 解决方法1：只设置一个 Partition 了，Topic 内的消息全局有序，这就变成了 RabbitMQ 那种结构。但这种结构不符合 Kafka 的设计理念，Topic 只有一个 Partition 就失去了扩展。 解决方法2：把某一类的消息都放入同一个 Partition，保证这组消息的局部有序。在发消息的时指定 Partition Key（如用户ID，订单号），Kafka 对其进行 Hash 计算，根据计算结果决定放入哪个 Partition。 Consumer消费者有序 RabbitMQ简单队列模型，Producer 有序，MQ 内消息有序，那么 一个Consumer 接收自然是有序的。 但是如果有多个Consumer，就有可能乱序 解决方法1：RabbitMQ只能使用一个 Consumer，必定全局有序。 解决方法2：仿照 Kafka 的 Partition Key ，拆为多个队列，把同组数据放入同一个队列，实现局部有序。 Kafka 中一个 Partition 只能对应一个 Consumer，故有序。 注意 要保证消费者有序，消费者不要使用多线程 ","link":"https://faxjiangyi.github.io/post/mq-xiao-xi-you-xu-xing-bao-zheng/"},{"title":"logback集成logstash","content":"原理及效果 ​ logstash支持从tcp输入，logback支持logstash appender，日志可以不打到文件直接打到logstash。方便集成ELK，且不挂载docker卷情况下镜像也不会增大。 步骤 应用-添加maven依赖 &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;/dependency&gt; 应用-logback-spring.xml添加appender &lt;appender name=&quot;logstash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;!--可以访问的logstash日志收集端口--&gt; &lt;destination&gt;127.0.0.1:8888&lt;/destination&gt; &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;/&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;Asia/Shanghai&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; { &quot;time&quot;:&quot;%d{yyyy-MM-dd HH:mm:ss}&quot;, &quot;level&quot;: &quot;%level&quot;, &quot;thread&quot;: &quot;%thread&quot;, &quot;class&quot;: &quot;%c[%L]&quot;, &quot;message&quot;: &quot;%msg&quot; } &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;logstash&quot; /&gt; &lt;/root&gt; logstash.conf ## 从tcp 8888端口输入 input { tcp { mode =&gt; &quot;server&quot; port =&gt; 8888 } } filter { json { source =&gt; &quot;message&quot; } } ## 控制台输出,测试用。也可以打到es output { stdout { codec =&gt; rubydebug } } ","link":"https://faxjiangyi.github.io/post/logback-ji-cheng-logstash/"},{"title":"一致性哈希算法","content":"问题举例 均衡负载问题：搭建Redis集群（3机），key落到哪台机？ 使用哈希算法 ​ 通过计算hash来求得hash值。 如公式 h=hash(key)%3，我们把Redis编号设置成0,1,2来保存对应hash计算出来的值，h的值等于Redis对应的编号。 但是hash算法也会面临容错性和扩展性的问题。 容错性：系统中的某个服务出现问题时，不能影响其他系统； 扩展性：加入新的服务器后，整个系统能正确高效运行。 ​ 现假设有一台Redis服务器宕机了，那么为了填补空缺，要将宕机的服务器从编号列表中移除，此时每个key就要按h = Hash(key) % 2重新计算。同样，如果新增一台服务器，规则也同样需要重新计算，h = Hash(key) % 4。 ​ 大量的key会重定向到其他服务器中，造成缓存命中率降低，而这种情况在分布式系统中是十分糟糕的。在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 一致性哈希算法 ​ 我们可以把一致哈希算法（Consistent hashing）看成是对 2^32 进行取模运算的结果值组织成一个圆环，这个圆环被称为哈希环。 一致性哈希要进行两步哈希： 对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希； 当对数据进行存储或访问时，对数据进行哈希映射； 对「数据」进行哈希映射得到一个结果，往顺时针的方向的找到第一个节点找到存储该数据的节点 假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置。可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。 假设节点数量从 3 减少到了 2，比如将节点 A 移除。可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B 结论 在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响，减少了扩缩容时的数据迁移量。 一致性哈希算法 + 虚拟节点 一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，可能会有大量的请求集中在一个节点上。如图，有一半以上的数据的寻址都会找节点 A，导致负载不均衡。 ​ 要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。 ​ 但问题是实际中我们没有那么多节点。所以这个时候我们就加入虚拟节点，也就是对一个真实节点做多个副本。 ​ 而且，有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对配置更好的节点增加更多的虚拟机节点。 结论 带虚拟节点的一致性哈希方法不仅适合节点扩缩容的场景，而且还能实现节点均衡分布，甚至支持节点硬件配置不同的场景（加权负载均衡）。 ","link":"https://faxjiangyi.github.io/post/yi-zhi-xing-ha-xi-suan-fa/"},{"title":"分表分页查询方案","content":"解决问题：分表后，查询T表，N页（X=(N-1)*Y）的Y条数据 [ 参考文献 ] : https://cloud.tencent.com/developer/article/1048654 [ 参考文献 ] : https://cloud.tencent.com/developer/article/2202460 -- 分库分表前的查询语句 select * from T order by time limit Y offset X 方案一 全局视野法 将 order by time limit Y offset X，改写成 order by time limit X+Y offset 0 ； 假设共分为N个库，服务层将得到N*(X+Y)条数据：即例子中的6页数据； 服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录，就是全局视野所需的一页数据。 优点 ​ sql修改简单，能够得到全局视野，业务精确无损。 缺点 每个分库都要进行查询； 每个分库都要返回更多的数据； 代码层面还要进行二次排序，增大了服务层的计算量； 随着页码的增大，返回数据增多，性能会急剧下降。 方案二 业务折衷-禁止跳页查询 产品不提供“直接跳到指定页面”的功能，而只提供“下一页”的功能。 将查询order by time offset X limit Y，改写成order by time where time &gt; ${上一页的最大值} limit Y 方案三 业务折衷-允许精度丢失 假设查询100页后的100条数据，两个分片； 将 offset 10000 limit 100 改写为 offset 5000 limit 50； 每个分库偏移5000（一半），获取50条数据（半页）； 得到的数据集进行合并，当然这一页数据并不是精准的。 方案四 二次查询法（终极方案） 假设查询200页后的5条数据，3个分片。 步骤一：查询改写 3个分片，改写为 select * from T order by time offset 333 limit 5，假设返回数据如下： 步骤二：找到返回全部数据的排序列最小值 ​ 定位到最小值是分库1的1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低： 步骤三：查询二次改写 第二次要改写成一个between语句，between起点是time_min，between的终点是各分库返回数据的最大值： -- 全局最小值1487501123 -- 第一个分库，第一次返回数据的最大值是 1487501523 select * from T order by time where time between 1487501123 and 1487501523; -- 第二个分库，第一次返回数据的最大值是 1487501323 select * from T order by time where time between 1487501123 and 1487501323; -- 第三个分库，第一次返回数据的最大值是 1487501553 select * from T order by time where time between 1487501123 and 1487501553; 相对第一次查询，第二次查询返回比第一次查询结果集更多的数据，假设三个分库返回的数据如下（粉底为多返回的数据）： 可以看到： 分库一：由于time_min来自原分库一，所以分库一的返回结果集和第一次查询相同； 分库二：头部的1条记录（time最小的记录）是新的（上图中粉色记录）； 分库三：头部的2条记录（time最小的2条记录）是新的（上图中粉色记录）。 步骤四：找到time_min在全局的offset 在每个结果集中虚拟一个time_min记录节点（红字）： 分库一：time_min在第一个库的offset是333； 分库二：1487501133的offset是333（根据第一次查询条件得出的），故倒推虚拟time_min在第二个库的offset是331； 分库三：1487501143的offset是333（根据第一次查询条件得出的），故倒推虚拟time_min在第三个库的offset是330。 综上，time_min在全局的offset是333+331+330=994。 步骤五：得到了time_min在全局的offset，根据二次查询结果，得出全局offset 1000 limit 5的记录 time_min的全局offset是994，去除合并后前7条数据（offset + 6 = 1000，994自己算一条），得出结果集（黄底数据） 优点 精确的返回业务所需数据，每不会随着翻页增加数据的返回量； 缺点 需要进行两次数据库查询。 ","link":"https://faxjiangyi.github.io/post/fen-biao-fen-ye-cha-xun-fang-an/"},{"title":"分表非Sharding-Key怎么查询","content":"假设：有用户表user，订单表order，order表通过user_id分表了，如何通过order_id查询订单？ 遍历 ​ 原始方法，union all查询所有遍历所有的order表。不建议，浪费大量系统资源。 引入外部缓存 ​ 将所有order信息冗余同步到ES，然后通过ES来查询。 索引表 ​ 建立user_id对应order_id表，先查询order_id对应的user_id，再通过user_id分表key查询对应的order表。 基因法 ​ 生成order_id时，将部分user_id包含到order_id中，通过order_id即可获取到相应user_id对应的order表。 基因法举例 如下图所示，user_id=20160169（二进制：1001100111001111010101001）的用户创建订单，order表16分片 使用user_id % 16 分片，决定这行数据要插入到哪个分片中； log (16, 2) = 4，分库基因是user_id的最后4个bit，即1001； 在生成order_id时，先使用一种分布式ID生成算法生成前60bit（图中青色部分）； 将分库基因加入到order_id的最后4个bit（图中粉色部分）； 拼装成最终的64bit订单order_id（图中蓝色部分）。 这样保证了同一个用户创建的所有订单都落到了同一个分片上，order_id的最后4个bit都相同，于是： 通过user_id %16 能够定位到分片； 通过order_id % 16 也能定位到分片。. ","link":"https://faxjiangyi.github.io/post/fen-biao-fei-sharding-key-zen-me-cha-xun/"},{"title":"G1和CMS区别","content":"CMS ​ CMS是基于并发的 &quot;标记-清理&quot; 算法实现的老年代收集器，以获取最短回收停顿时间为目标。 CMS回收垃圾的4个阶段 初始标记（Stop The World）：独占CPU，仅标记GC-Roots能直接关联的对象； 并发标记：可以和用户线程并行执行，标记所有可达对象； 重新标记（Stop The World）：独占CPU，对并发标记阶段用户线程运行产生的垃圾对象进行标记修正； 并发清理：可以和用户线程并行执行，清理垃圾。 CMS优缺点 优点 并发收集，低停顿。 缺点 内存空间碎片：“标记-清理”算法会产生大量的空间碎片，会出现老年代空间很大但无法找到连续空间来分配当前对象，提前触发一次FullGC； 对CPU敏感：在并发阶段虽然不会导致用户线程停顿，但是会因为占用了一部分线程使应用程序变慢，适用于老年代并不频繁GC的场景； 无法处理浮动垃圾：在最后一步并发清理的过程中，用户线程执行也会产生垃圾，但是这部分垃圾是在标记之后，所以只有等到下一次GC的时候清理掉，这部分垃圾叫浮动垃圾。 G1 ​ JDK9以后的默认GC，基于&quot;标记-整理&quot;算法，将内存进行Region分区，不区分新生代老生代，除了追求低停顿外，还能建立可预测的停顿时间 。 G1回收垃圾的4个阶段 初始标记（Stop the World）：标记GC Roots 可以直接关联的对象，该阶段需要CPU独占 ，但是耗时短； 并发标记：从GC Roots开始堆中对象进行可达性分析，寻找存活的对象，可以与其他程序并发执行，耗时较长； 最终标记（Stop the World）：并发标记期间用户程序会导致标记记录产生变动（好比一个阿姨一边清理垃圾，另一个人一边扔垃圾）虚拟机会将这段时间的变化记录在Remembered Set Logs 中。最终标记阶段会向Remembered Set合并并发标记阶段的变化。这个阶段需要 Stop the World ，也可以并发执行； 筛选回收（Stop the World）：对每个Region的回收成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。Sun公司透露这个阶段其实也可以做到并发，但考虑到停顿线程将大幅度提高收集效率，所以选择停顿。 G1优缺点 优点 可以设定停顿时间的目标，相比于CMS，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多； 避免内存碎片：“标记-整理”算法的好处，尤其是当 Java 堆非常大的时候，G1 的优势更加明显。 缺点 G1 需要Remembered Set (卡表)来记录引用关系，这种数据结构占用大量内存，可能达到整个堆内存容量的 20% 甚至更多。 G1和CMS的区别 G1从整体上来看是 标记-整理 算法，但从局部（两个Region之间）是标记-复制算法。而CMS是 标记-清除算法。G1不会产生内存碎片，而CMS会产生内存碎片； CMS使用了 写后屏障来维护卡表，而G1不仅使用了写后屏障来维护卡表，还是用了 写前屏障来跟踪并发时的指针变化情况（为了实现原始快照）； CMS对Java堆内存使用的是传统的新生代和老年代划分方法，而G1使用的全新的Region划分方法； CMS收集器只收集老年代，可以配合新生代的Serial和ParNew收集器一起使用；G1收集器收集范围是老年代和新生代，不需要结合其他收集器； CMS使用 增量更新解决并发标记下出现的错误标记问题，而G1使用原始快照解决； 按照《深入理解Java虚拟机》作者说法，CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6~8GB。 什么情况下应该考虑使用G1 官方文档： 实时数据占用超过一半的堆空间； 对象分配或者晋升的速度变化大； 希望消除长时间的GC停顿（超过0.5-1秒）； 内存大于8GB。 ","link":"https://faxjiangyi.github.io/post/g1-he-cms-qu-bie/"},{"title":"Docker的网络模式","content":"bridge模式，host模式，container模式，none模式 [ 参考链接 ] : https://segmentfault.com/a/1190000040335988 docker底层通过linux的Namespace进行隔离，其中网络隔离有以下几种方案： bridge模式(默认) ​ 当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。 ​ 通过端口映射对外暴露。 host模式 ​ host模式，容器和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是文件系统、进程列表等还是和宿主机隔离的。 ​ host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。 ​ 端口暴露直接与宿主机一致。 container模式 ​ 这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。 none模式 ​ Docker容器拥有自己的Network Namespace，但是并不为Docker容器进行任何网络配置。 ","link":"https://faxjiangyi.github.io/post/docker-de-wang-luo-mo-shi/"},{"title":"Redis持久化 RDB和AOF","content":"[ 参考文献 ] : https://juejin.cn/post/6844903939339452430 RDB快照持久化 ​ RDB持久化会生成RDB文件，该文件是一个压缩过的二进制文件，可以通过该文件还原快照时的数据库状态，即生成该RDB文件时的服务器数据。 ​ RDB文件默认为当前工作目录下的dump.rdb 触发方法 执行save和bgsave命令：save会阻塞redis服务器进程，bgsave会fork一个子进程（见图），服务器进程会继续处理命令请求； 配置文件设置save &lt;seconds&gt; &lt;changes&gt;规则，自动间隔性执行bgsave命令：seconds秒内，至少有changes次变化，就会自动触发bgsave命令； 主从复制时，从库全量复制同步主库数据，主库会执行bgsave； 执行flushall命令清空服务器数据； 执行shutdown命令关闭Redis时，会执行save命令。 AOF持久化 ​ AOF（Append Only File）持久化功能，AOF持久化会把被执行的写命令（Redis的序列化协议RESP）写到AOF文件的末尾，记录数据的变化。 ​ 默认情况下，Redis是没有开启AOF的，开启后，每执行一条更改Redis数据的命令，都会把该命令追加到AOF文件中，这是会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外SSD可以提高AOF的性能。 文件写入(write)和文件同步(fsync) 操作系统的write命令会缓冲限流，fsync会强制写硬盘但是效率较低，Redis提供了以下fsync策略： appendfsync always：每个写命令同步写入磁盘 appendfsync everysec（默认值）：将aof_buf缓存区的内容写入AOF文件，每秒同步一次，该操作由一个线程专门负责 appendfsync no：由操作系统来决定写入文件 AOF重写 ​ AOF文件中通常会有一些冗余命令，如：过期数据的命令、无效的命令（重复设置、删除）、多个命令可合并为一个命令（批处理命令）。故AOF提供了压缩空间的重写命令（流程见下图），有以下触发方式： 手动触发：bgrewriteaof，与bgsave触发快照时类似的，都是fork一个子进程执行； 自动触发会：根据以下参数配置来自动执行bgrewriteaof命令： # 表示当AOF文件的体积大于64MB，且AOF文件的体积比上一次重写后的体积大了100%时，会执行`bgrewriteaof`命令 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb RDB和AOF优缺点 RDB 优点 保存着某个时间点的完整数据集，适合做数据的备份，灾难恢复； 可以最大化Redis的性能，只需fork一个子进程来完成RDB文件的创建，父进程不需要做IO操作； 与AOF相比，恢复大数据集的时候会更快； 缺点 数据安全性不如AOF，根据配置可能要几分钟才快照一次，如果服务器宕机，就可能丢失几分钟的数据； Redis数据集较大时，fork的子进程要完成快照会比较耗CPU、耗时； AOF 优点 数据更完整，秒级数据丢失（取决fsync策略，如果是everysec，最多丢失1秒的数据）； AOF文件是一个只进行追加的日志文件，且写入操作是以Redis协议的格式保存的，内容可读，适合误删紧急恢复； 缺点 对于相同的数据集，AOF文件的体积要大于RDB文件，数据恢复也会比较慢； 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 不过在一般情况下，每秒 fsync 的性能依然非常高。 ","link":"https://faxjiangyi.github.io/post/redis-chi-jiu-hua-rdb-he-aof/"},{"title":"RabbitMQ延时队列","content":"[ 参考文献 ] : https://juejin.cn/post/7048936544207372324 实现逻辑 ​ 在电商行业中，通常都会有一个需求：订单超时未支付，自动取消该订单。那么通过RabbitMQ实现的延时队列就是实现该需求的一种方式。 ​ RabbitMQ本身是具有死信队列和死信交换机属性的，延时队列 可以通过死信队列和死信交换机来实现。 死信的条件 消息被消费者拒绝（basic.reject 或者 back.nack），且 requeue=false； 消息过期，因为队列设置了TTL（Time To Live）时间； 消息被丢弃，因为超过了队列的长度限制。 延时队列的实现流程 创建&quot;死信交换机&quot;； 创建&quot;死信队列&quot;，&quot;死信队列&quot;没有消费者； 给&quot;死信队列&quot;设置&quot;死信交换机&quot;及死信路由key； 创建&quot;死信下游队列&quot;； 给&quot;死信下游队列&quot;绑定&quot;死信交换机&quot;及路由key； 发布消息到&quot;死信队列&quot;，并设置TTL（延时时间）； 消费&quot;死信下游队列&quot;。 ","link":"https://faxjiangyi.github.io/post/rabbitmq-yan-shi-dui-lie/"},{"title":"MySQL行锁-事务锁排查方法","content":"[ 参考文档 ] : https://bbs.huaweicloud.com/blogs/363270 基本流程-找到被阻塞的SQL ​ 一般到这里就可以了，找到SQL开发进行代码排查 -- 查当前行锁数量（确认有锁） -- 重点字段： -- Innodb_row_lock_current_waits 当前等待锁的数量（重点关注） -- Innodb_row_lock_time_max 从系统启动算起，等待锁最长的一次时间 SHOW status like 'innodb_row_lock%'; -- 查等正在等待锁的事务（被阻塞） -- 重点字段： -- trx_id 事务ID -- trx_state 事务状态 RUNNING进行中 / LOCK WAIT等待中 / ROLLING BACK回滚中 / COMMITTING提交中 （关注LOCK WAIT） -- trx_query 被阻塞的语句（通过这个来知道是哪个sql被阻塞） SELECT * FROM information_schema.INNODB_TRX WHERE trx_state='LOCK WAIT'; 进阶流程-找到持有锁的SQL ​ 可以进一步找到占有的SQL，一般可以在基本流程中通过代码排查找到 -- 查持正在持有锁的进程（正在占用） -- 重点字段： -- blocking_pid 锁源的进程ID（相当于process_id，与show full processlist的id对应） -- blocking_trx_id 锁源的事务ID -- waiting_trx_id 等待中的事务id号（与查询等待中的trx_id对应） -- locked_table 锁源占用的表 -- locked_index 上锁的索引 -- locked_type 锁的类型 行级锁(Record Lock)、间隙锁(Gap Lock)、自增锁（Next-Key Lock） -- waiting_query 被阻塞的SQL（与查询等待中的trx_query对应） SELECT * FROM sys.innodb_lock_waits; -- 根据 process_id 找到 锁源的sql线程id（即 thread_id） -- 重点字段： -- THREAD_ID 锁源的thread_id SELECT * FROM performance_schema.threads WHERE processlist_id = #{blocking_pid}; -- 根据 thread_id 找到 持有锁的SQL -- 重点字段： -- thread_id 线程ID -- sql_text 锁源的sql语句 SELECT * FROM performance_schema.events_statements_current WHERE thread_id = #{thread_id}; -- 也可以根据 thread_id 找到 该进程历史执行的SQL -- 重点字段： -- thread_id 线程ID -- sql_text 该 thread 历史执行SQL SELECT * FROM performance_schema.events_statements_history WHERE thread_id = #{thread_id}; ​ SQL组合，一部到位 SELECT -- 锁源的进程ID w.blocking_pid, -- 锁源的事务ID w.blocking_trx_id, -- 阻塞的事务ID w.waiting_trx_id, -- 锁的表 w.locked_table, -- 锁类型 w.locked_type, -- 被阻塞的SQL w.waiting_query, -- 锁源的SQL c.SQL_TEXT FROM -- 锁等待表 `sys`.innodb_lock_waits w, -- 线程表 `performance_schema`.threads t, -- 线程当前事件表 `performance_schema`.events_statements_current c WHERE w.blocking_pid = t.processlist_id AND t.THREAD_ID = c.THREAD_ID; ","link":"https://faxjiangyi.github.io/post/mysql-xing-suo-shi-wu-suo-pai-cha-fang-fa/"},{"title":"消息质量QoS如何保证","content":"MQTT 提供了 QoS 机制，设计了多种消息交互机制来提供不同的服务质量，满足用户在各种场景下对消息可靠性的要求。 [ 参考文献 ] ： https://www.emqx.com/zh/blog/introduction-to-mqtt-qos QoS 0 - 最多一次 ​ QoS 0 消息的分发依赖于底层网络的能力。发布者只会发布一次消息，接收者不会应答消息，发布者也不会储存和重发消息。 QoS 1 - 最少一次 ​ 简单的 ACK 机制来保证 QoS 1。发布者会发布消息，并等待接收者的 PUBACK 报文的应答，如果在规定的时间内没有收到 PUBACK 的应答，发布者会将消息的 DUP 置为 1 并重发消息。 QoS 2 - 精确一次 ​ 发布者发布 QoS 为 2 的消息之后，会将消息储存并等待接收者回复 PUBREC，发送者收到 PUBREC 后就可以安全丢弃消息，因为它已经知道接收者成功收到消息。 ​ 发布者会保存 PUBREC 消息并应答一个 PUBREL，等待接收者回复 PUBCOMP 消息，当发送者收到 PUBCOMP 消息之后会清空保存的状态。 ​ 接收者接收QoS 为 2 的 PUBLISH 消息时，他会存储此消息并返回一条 PUBREC 进行应答。当接收者收到 PUBREL 消息之后，会清空保存的状态，并回复 PUBCOMP。 ​ 订阅者收到PUBREL后，才会将存储的消息体发布出去。 ​ 本质：QoS 1作消息存储 + PUBREL作实际发布。 ","link":"https://faxjiangyi.github.io/post/xiao-xi-zhi-liang-qos-ru-he-bao-zheng/"},{"title":"胖Model和瘦Model","content":"MVC M应该做的事 ​ 给ViewController提供数据 给ViewController存储数据提供接口 提供经过抽象的业务基本组件，供Controller调度 C应该做的事 ​ 管理View Container的生命周期 负责生成所有的View实例，并放入View Container 监听来自View与业务有关的事件，通过与Model的合作，来完成对应事件的业务。 V应该做的事 ​ 界面元素表达，响应与业务无关的事件，并因此引发动画效果，点击反馈等。 什么是胖Model 和瘦Model? ​ 胖Model就是在model 中进行一些处理,让VC只是用很少的代码逻辑处理即可完成的一种模式。 ​ 瘦Model就是在model中不进行任何处理,让VC全部操作 我们在MVC中经常使用的thin model。 DDD 在DDD中，瘦Model类似DTO，胖Model则包含持久层CRUD操作。 ","link":"https://faxjiangyi.github.io/post/pang-model-he-shou-model/"},{"title":"Mybatis的一级缓存和二级缓存","content":"[参考文献] : https://www.cnblogs.com/happyflyingpig/p/7739749.html 一级缓存 ​ Mybatis对缓存提供支持，但是在没有配置的默认情况下，它只开启一级缓存。 ​ 在参数和SQL完全一样的情况下，我们使用同一个SqlSession对象调用一个Mapper方法，往往只执行一次SQL。因为使用SelSession第一次查询后，MyBatis会将其放在缓存中，以后再查询的时候，如果没有声明需要刷新，并且缓存没有超时的情况下，SqlSession都会取出当前缓存的数据，而不会再次发送SQL到数据库。 一级缓存的生命周期 MyBatis在开启一个数据库会话时，会创建一个新的SqlSession对象，SqlSession对象中会有一个新的Executor对象。Executor对象中持有一个新的PerpetualCache对象；当会话结束时，SqlSession对象及其内部的Executor对象还有PerpetualCache对象也一并释放掉。 如果SqlSession调用了close()方法，会释放掉一级缓存PerpetualCache对象，一级缓存将不可用。 如果SqlSession调用了clearCache()，会清空PerpetualCache对象中的数据，但是该对象仍可使用。 SqlSession中执行了任何一个update操作(update()、delete()、insert()) ，都会清空PerpetualCache对象的数据，但是该对象可以继续使用 简单来说 ​ 一级缓存生命周期是一个SqlSession，任何通过该SqlSession的更新操作，或主动调用清除缓存，都会清除缓存。 二级缓存 ​ 二级缓存默认是不开启的，作用于同一个Mapper下同一个namespace，可以自行配置开启，并实现缓存的存取（接入redis等）。 二级缓存的开启 MyBatis要求返回的POJO必须是可序列化的(实现Serializable，并且写uid)； mybatis-config.xml添加开启二级缓存的语句 &lt;configuration&gt; &lt;settings&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot; /&gt; &lt;/settings&gt; &lt;/configuration&gt; 在映射XML文件（Mapper文件）配置二级缓存使用 &lt;mapper namespace=&quot;com.yihaomen.mybatis.dao.StudentMapper&quot;&gt; &lt;!-- eviction: 缓存回收策略，目前MyBatis提供以下策略。 (1) LRU,最近最少使用的，移除最长时间不用的对象 (2) FIFO,先进先出，按对象进入缓存的顺序来移除他们 (3) SOFT,软引用，移除基于垃圾回收器状态和软引用规则的对象 (4) WEAK,弱引用，更积极的移除基于垃圾收集器状态和弱引用规则的对象。 flushInterval: 刷新间隔时间（毫秒），这里配置的是30秒刷新，如果你不配置它，那么当SQL被执行的时候才会去刷新缓存。 size: 缓存对象个数，不宜设置过大。设置过大会导致内存溢出。 readOnly: 缓存是否只读。 type: 自实现org.apache.ibatis.cache.Cache子类，可接入redis --&gt; &lt;cache eviction=&quot;LRU&quot; flushInterval=&quot;30000&quot; size=&quot;1024&quot; readOnly=&quot;true&quot; type=&quot;path.to.your.cache.implementation&quot;/&gt; &lt;!--通过useCache设置来开启缓存--&gt; &lt;select id=&quot;listAll&quot; useCache=&quot;true&quot;&gt; SELECT * FROM student &lt;/select&gt; &lt;!-- 刷新二级缓存 --&gt; &lt;delete id=&quot;deleteById&quot; flushCache=&quot;true&quot;&gt; DELETE FROM student WHERE id = #{id} &lt;/delete&gt; &lt;/mapper&gt; 编写org.apache.ibatis.cache.Cache缓存实现子类，以下是该接口源码，可自行实现接入 redis package org.apache.ibatis.cache; import java.util.concurrent.locks.ReadWriteLock; /** * 参考实现代码：https://blog.csdn.net/xushiyu1996818/article/details/89215428 **/ public interface Cache { /**![](https://faxjiangyi.github.io/post-images/1699328231064.png) * 缓存ID **/ public abstract String getId(); /** * 写入缓存 **/ public abstract void putObject(Object key, Object value); /** * 获取缓存 **/ public abstract Object getObject(Object key); /** * key删除缓存 **/ public abstract Object removeObject(Object key); /** * 清除所有缓存 **/ public abstract void clear(); /** * 缓存大小 **/ public abstract int getSize(); /** * 获取锁 **/ public abstract ReadWriteLock getReadWriteLock(); } ","link":"https://faxjiangyi.github.io/post/mybatis-de-yi-ji-huan-cun-he-er-ji-huan-cun/"},{"title":"什么是倒排索引","content":"概念 ​ 倒排索引（英语：Inverted index），也常被称为反向索引，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。 倒排索引有两种不同的形式： ​ 一条记录的水平反向索引：包含每个引用单词的文档的列表。 ​ 一个单词的水平反向索引：又包含每个单词在一个文档中的位置。 后者的形式提供了更多的兼容性（比如短语搜索），但是需要更多的时间和空间来创建。 现代搜索引擎的索引都是基于倒排索引。相比“签名文件”、“后缀树”等索引结构，“倒排索引”是实现单词到文档映射关系的最佳实现方式和最有效的索引结构。 为什么叫倒排索引 由于正常的数据结构是通过记录来确定属性，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。 举例： ​ 关系数据库中，先找到行，再找到对应的值； ​ 倒排索引中，先找到值，再找到对应的行。 过程 索引创建过程 输入原始数据并进行编号，形成文档列表 按照分词库进行单词拆分，得到词条。对词条进行编号，以词条创建索引。然后记录下包含该词条的所有文档编号（及其它信息）。 ","link":"https://faxjiangyi.github.io/post/shi-me-shi-dao-pai-suo-yin/"},{"title":"Dindin","content":" ","link":"https://faxjiangyi.github.io/post/dindin/"},{"title":"多线程死锁的产生和解决","content":"死锁的定义，死锁产生的原因，死锁产生的条件，避免死锁的方法 死锁的定义 ​ 死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。 产生死锁的原因 竞争不可抢占性资源 ​ p1已经打开F1，想去打开F2，p2已经打开F2，想去打开F1，但是F1和F2都是不可抢占的，这是发生死锁。 竞争可消耗资源引起死锁 ​ 进程间通信，如果顺序不当，会产生死锁，比如p1发消息m1给p2，p1接收p3的消息m3，p2接收p1的m1，发m2给p3，以此类推，如果进程之间是先发信息的那么可以完成通信，但是如果是先接收信息就会产生死锁。 进程推进顺序不当 ​ 进程在运行过程中，请求和释放资源的顺序不当，也同样会导致产生进程死锁。 产生死锁的四个必要条件 互斥性：线程对资源的占有是排他性的，一个资源只能被一个线程占有，直到释放。 请求和保持条件：一个线程对请求被占有资源发生阻塞时，对已经获得的资源不释放。 不剥夺：一个线程在释放资源之前，其他的线程无法剥夺占用。 循环等待：发生死锁时，线程进入死循环，永久阻塞。 避免死锁的方法 破坏“请求和保持”条件 ​ 想办法，让进程不要那么贪心，自己已经有了资源就不要去竞争那些不可抢占的资源。比如，让进程在申请资源时，一次性申请所有需要用到的资源，不要一次一次来申请，当申请的资源有一些没空，那就让线程等待。不过这个方法比较浪费资源，进程可能经常处于饥饿状态。还有一种方法是，要求进程在申请资源前，要释放自己拥有的资源。 破坏“不可抢占”条件 ​ 允许进程进行抢占，方法一：如果去抢资源，被拒绝，就释放自己的资源。方法二：操作系统允许抢，只要你优先级大，可以抢到。 破坏“循环等待”条件 ​ 将系统中的所有资源统一编号，进程可在任何时刻提出资源申请，但所有申请必须按照资源的编号顺序（升序）提出 ","link":"https://faxjiangyi.github.io/post/si-suo-de-chan-sheng-he-jie-jue/"},{"title":"缓存一致性解决方案","content":"实际项目中，在一些QPS比较高的场景下，经常引入缓存来缓解数据库的查询压力，以缓存的空间来换取查询效率的提升。但是一旦引入了缓存，就一定会遇到缓存中的数据与数据库中的数据如何保持一致的问题，本文就是针对两者之间的数据一致性问题进行分析。 [参考文献] : https://mp.weixin.qq.com/s/nqyQZxuprbSHvx_IoNtTeA 先写数据库再写缓存 ​ 由于引入了Redis缓存，数据会保存在数据库以及Redis中，这就带来了另一个头痛的问题，如何保证两边的数据一致性，到底是先更新数据库还是先更新Redis缓存呢？增加缓存之后由于涉及到数据库和Redis两边的数据写入时机问题，当进行业务数据写入的时候，如果先写入数据库再写入Redis缓存，那么就会出现这样的问题， ​ 如果数据库写入成功，而Redis写入失败，那么数据库中就是最新值，缓存中为旧值，出现数据不一致，如果此时查询数据的时候就会查询到旧值，从而导致业务数据异常。 先写缓存再写数据库 ​ 另外一种方案，如果先更新Redis再更新数据库，但是Redis缓存更新成功了，数据库更新失败了，那么就说明缓存中为业务最新值，而数据库中是业务旧值，那么此时进行数据查询的时候服务可以获取到最新值，但是过一段时间缓存失效之后，又会从数据库中获取到旧值，又会出现数据不一致的情况。 Cache Aside Pattern ​ 这是比较经典的解决方案，总的来说就是在数据查询的时候： （1）先查询缓存，如果缓存中有数据的话直接返回缓存中的数据； （2）如果缓存中没有数据，则从数据库中进行数据获取，而后再将查询到的数据更新到缓存中； （3）在进行数据数据更新的时候，先更新数据库，再删除缓存； ​ 这个方案比较特殊的部分就是在于更新数据的时候主动删除缓存，一般情况下都是更新完数据库再更新缓存。那为什么这个方案中却主动删除缓存呢？其实我觉得这是种小聪明的偷懒行为，为什么这么说，因为缓存中的数据实际上有的不仅仅是数据库表中某个字段的值，而是多个数据计算之后的值，另外如果这些缓存被访问的频率不是很高的话，如果每次更新数据库的时候都要进行缓存，那就有点资源浪费了。因此通过这种删除缓存的方法，同时复用了无缓存从数据坤获取数据后更新缓存的流程，实际也是一种懒加载的思想。 如何保证第二步骤执行成功？ ​ 正如前文所说的，无论是新更新缓存还是先删除缓存，都涉及到如何让第二步骤的执行保证成功，最直接的办法就是实现重试。但是重试也不是说说这么简单的，重试也可能还是失败，重试的次数到底怎么控制重试多少次才合理呢？另外如果一直重试的话，线程无法响应客户端请求也是个问题。因此比较好的处理方法就是实现异步重试。我们可以将重试的请求放到一个消息队列中，让消费者去干这个事情。 ​ 不过还有一个值得注意的问题，就是在设置缓存的时候，需要设置缓存对应的过期时间。为什么这么说呢？因为对于缓存来说，实际上有个命中率的问题，并不是在缓存中的数据都是被高频率访问的，有的数据命中率实际并不高，因此通过设置缓存的过期时间可以提高Redis的内存使用效率。另外其实设置缓存也是一种兜底的策略，就是当数据出现不一致的情况时，至少有个过期时间可以让缓存中的数据失效，从而从数据库中重新获取最新的数据来更新缓存。 缓存的最初的目的是什么 ​ 这一路看上去似乎方案都不是很完美，我们能做到严格的强一致性么？做到是可以做到，但是不容易，为了保证数据一致性付出的代价也会很大。所以我们回到引入缓存的最初的目的到底是什么，是为了提升平台的性能，但是如果为了数据的强一致反而降低了性能，是不是一种画虎不成反类犬的感觉。 ​ 因此既然我们引入了缓存，就需要在一定程度上去容忍数据一致性的问题。但是同时我们需要有一定的措施来提升健壮性，比如增加重试机制，比如设置缓存失效时间来进行数据兜底，从而达到数据的最终一致。性能和一致性就像鱼和熊掌，虽然我们都爱，但是总要有取舍，总要有平衡。 ","link":"https://faxjiangyi.github.io/post/huan-cun-yi-zhi-xing-jie-jue-fang-an/"},{"title":"集合迭代时修改元素","content":"示例代码 public class ListAddMain { public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;1&quot;); list.add(&quot;2&quot;); list.add(&quot;3&quot;); for (String s : list) { System.out.println(s); if(&quot;1&quot;.equals(s)) { list.remove(s); } } } } // ---------- 输出 ----------------- /* 1 Exception in thread &quot;main&quot; java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:911) at java.util.ArrayList$Itr.next(ArrayList.java:861) at pers.jy.demo.modules.test.yst.ListAddMain.main(ListAddMain.java:20) */ 原因 ​ modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了会抛出 ConcurrentModificationException。 ​ 关键点就在于：调用list.remove()方法导致modCount和expectedModCount的值不一致。 ​ 注意，像使用for-each进行迭代实际上也会出现这种问题。 解决方案 单线程 ​ 使用list.iterator()来进行迭代，调用itr.remove()方法（itr.remove()方法有修改modCount的代码）。 多线程 在使用iterator迭代的时候使用synchronized或者Lock进行同步； 使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。 ","link":"https://faxjiangyi.github.io/post/ji-he-die-dai-shi-xiu-gai-yuan-su/"},{"title":"static关键字","content":"静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 public class A { private int x; // 实例变量 private static int y; // 静态变量 public static void main(String[] args) { // int x = A.x; // Non-static field 'x' cannot be referenced from a static context A a = new A(); int x = a.x; int y = A.y; } } 静态方法 静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字，因为这两个关键字与具体对象关联。 public abstract class A { public static void func1(){ } } 静态语句块 静态语句块在类初始化时运行一次。 public class A { static { System.out.println(&quot;123&quot;); } public static void main(String[] args) { A a1 = new A(); A a2 = new A(); } } 静态内部类 非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。 静态内部类不能访问外部类的非静态的变量和方法。 public class OuterClass { class InnerClass { } static class StaticInnerClass { } public static void main(String[] args) { // InnerClass innerClass = new InnerClass(); // 'OuterClass.this' cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); } } 静态导包 在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 import static com.xxx.ClassName.* 初始化顺序 静态变量和静态语句块优先于实例变量和普通语句块 静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 最后才是构造函数的初始化。 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 示例代码 public class StaticMain { static { System.out.println(&quot;静态语句块-前&quot;); } static { System.out.println(&quot;静态语句块-后&quot;); } { System.out.println(&quot;普通语句块&quot;); } public StaticMain() { System.out.println(&quot;构造函数&quot;); } public static void main(String[] args) { System.out.println(&quot;实例化1&quot;); StaticMain sm = new StaticMain(); System.out.println(&quot;实例化2&quot;); StaticMain sm2 = new StaticMain(); } } // ---------------输出---------------- /* 静态语句块-前 静态语句块-后 实例化1 普通语句块 构造函数 实例化2 普通语句块 构造函数 */ ","link":"https://faxjiangyi.github.io/post/static-guan-jian-zi/"},{"title":"String, StringBuffer 和 StringBuilder ","content":"可变性 String 不可变 StringBuffer StringBuilder 可变 线程安全 String 不可变，因此是线程安全的 StringBuffer 是线程安全的，内部使用 synchronized 进行同步 StringBuilder 不是线程安全的 ","link":"https://faxjiangyi.github.io/post/string-stringbuffer-he-stringbuilder/"},{"title":"String为什么是不可变的","content":"为什么说String是不可变的 看String类源码，String本质是char数组，且成员用了private和final修饰； 虽说final修饰只是相应的地址不可变，String类源码也没有更改char数组元素的相关代码； Java设计师还把整个String设成final禁止继承，避免被其他人继承后破坏； 给一个已有字符串如&quot;abc&quot;第二次赋值成&quot;abcd&quot;，不是在原内存地址上修改数据，而是重新指向一个新对象，新地址。 不可变的好处 1. 可以缓存 hash 值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 2. String Pool 的需要 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 3. 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。 4. 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 ","link":"https://faxjiangyi.github.io/post/string-wei-shi-me-shi-bu-ke-bian-de/"},{"title":"@Transactional不配置rollBackFor的情况","content":"不配置rollbackFor的情况：默认抛出RuntimeExeception时会回滚 配置rollbackFor的情况：按抛出的异常进行捕捉回滚 参考文档org.springframework.transaction.annotation.Transactional /** * Describes transaction attributes on a method or class. * * &lt;p&gt;This annotation type is generally directly comparable to Spring's * {@link org.springframework.transaction.interceptor.RuleBasedTransactionAttribute} * class, and in fact {@link AnnotationTransactionAttributeSource} will directly * convert the data to the latter class, so that Spring's transaction support code * does not have to know about annotations. If no rules are relevant to the exception, * it will be treated like * {@link org.springframework.transaction.interceptor.DefaultTransactionAttribute} * (rolling back on runtime exceptions). * * &lt;p&gt;For specific information about the semantics of this annotation's attributes, * consider the {@link org.springframework.transaction.TransactionDefinition} and * {@link org.springframework.transaction.interceptor.TransactionAttribute} javadocs. * * @author Colin Sampaleanu * @author Juergen Hoeller * @since 1.2 * @see org.springframework.transaction.interceptor.TransactionAttribute * @see org.springframework.transaction.interceptor.DefaultTransactionAttribute * @see org.springframework.transaction.interceptor.RuleBasedTransactionAttribute */ ","link":"https://faxjiangyi.github.io/post/transactional-bu-pei-zhi-rollbackfor-de-qing-kuang/"},{"title":"面向对象六大设计原则(SOLID)","content":"单一职责原则，开闭原则，里氏替换原则，迪米特法则，接口隔离原则，依赖倒置原则 单一职责原则（Single Responsibility Principle） 一个类应该只有一个发生变化的原因 开闭原则（Open Closed Principle） 一个软件实体，如类、模块和函数应该对扩展开放，对修改关闭 里氏替换原则（Liskov Substitution Principle） 所有引用基类的地方必须能透明地使用/更换其子类的对象 迪米特法则（Law of Demeter） 只与你的直接朋友交谈，不跟“陌生人”说话（如无必要，勿增烦恼） 接口隔离原则（Interface Segregation Principle） 1、客户端不应该依赖它不需要的接口。 2、类间的依赖关系应该建立在最小的接口上。 依赖倒置原则（Dependence Inversion Principle） 1、上层模块不应该依赖底层模块，它们都应该依赖于抽象。 2、抽象不应该依赖于细节，细节应该依赖于抽象。 ","link":"https://faxjiangyi.github.io/post/mian-xiang-dui-xiang-liu-da-she-ji-yuan-ze-solid/"},{"title":"IaaS Paas和SaaS","content":"SaaS软件即服务 ​ 软件即服务（也称为云应用程序服务）代表了云市场中企业最常用的选项。 SaaS利用互联网向其用户提供应用程序，这些应用程序由第三方供应商管理。 大多数SaaS应用程序直接通过Web浏览器运行，不需要在客户端进行任何下载或安装。 ​ 举例：XXX-CRM系统、Gmail PaaS平台即服务 ​ 云平台服务或平台即服务（PaaS）为某些软件提供云组件，这些组件主要用于应用程序。 PaaS为开发人员提供了一个框架，使他们可以基于它创建自定义应用程序。所有服务器，存储和网络都可以由企业或第三方提供商进行管理，而开发人员可以负责应用程序的管理。 ​ 举例：阿里云MySQL、阿里云Elastic IaaS基础架构即服务 ​ 云基础架构服务称为基础架构即服务（IaaS），由高度可扩展和自动化的计算资源组成。 IaaS是完全自助服务，用于访问和监控计算、网络，存储和其他服务等内容，它允许企业按需求和需要购买资源，而不必购买全部硬件。 ​ 举例：阿里云、AWS 形象说明 以&quot;做饭&quot;为例： IaaS: 给你厨房、水电、炉灶、电饭煲 Paas: 菜也给你买好了 Saas: 我做饭给你吃 图例说明 ","link":"https://faxjiangyi.github.io/post/iaas-paas-he-saas/"},{"title":"什么是缓存雪崩、穿透、击穿？","content":"雪崩 一句话总结 ​ 在高并发下，大量缓存key在同一时间失效，大量请求直接落在数据库上，导致数据库宕机。 解决方案 不设置过期时间 ； 设置随机过期时间，避免大量key集体失效； 若是集群部署，可将热点数据均匀分布在不同的Redis库中也能够避免key全部失效问题； 跑定时任务，在缓存失效前刷进新的缓存。 穿透 一句话总结 ​ Redis缓存和数据库中没有相关数据(例用户直接携带id=-1的参数不断发起请求)，redis中没有这样的数据，无法进行拦截，直接被穿透到数据库，导致数据库压力过大宕机。 解决方案 对不存在的数据缓存到Redis中，设置key，value值为null(不管是数据未null还是系统bug问题)，并设置一个短期过期时间段，避免过期时间过长影响正常用户使用； 拉黑该IP地址； 对参数进行校验，不合法参数进行拦截 ； 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap(位图)中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 击穿 一句话总结 ​ 某一个热点key，在不停地扛着高并发，当这个热点key在失效的一瞬间，持续的高并发访问就击破缓存直接访问数据库，导致数据库宕机。 解决方案 不设置过期时间； 加互斥锁：上面的现象是多个线程同时去查询数据库的这条数据，加上互斥锁，等第一个线程查询到了数据，然后将数据放到Redis缓存起来。后面的线程进来发现已经有缓存了，就直接走缓存。 ","link":"https://faxjiangyi.github.io/post/shi-me-shi-huan-cun-xue-beng-chuan-tou-ji-chuan/"},{"title":"为什么TCP需要三次握手、四次挥手","content":"三次握手 谢希仁版《计算机网络》中的例子： ​ 已失效的连接请求报文段” 的产生在这样一种情况下：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。 ​ 假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。 四次挥手 因为TCP是全双工通信的 （1）第一次挥手 ​ 因此当主动方发送断开连接的请求（即FIN报文）给被动方时，仅仅代表主动方不会再发送数据报文了，但主动方仍可以接收数据报文。 （2）第二次挥手 ​ 被动方此时有可能还有相应的数据报文需要发送，因此需要先发送ACK报文，告知主动方“我知道你想断开连接的请求了”。这样主动方便不会因为没有收到应答而继续发送断开连接的请求（即FIN报文）。 （3）第三次挥手 ​ 被动方在处理完数据报文后，便发送给主动方FIN报文；这样可以保证数据通信正常可靠地完成。发送完FIN报文后，被动方进入LAST_ACK阶段（超时等待）。 （4）第四挥手 ​ 如果主动方及时发送ACK报文进行连接中断的确认，这时被动方就直接释放连接，进入可用状态。 ","link":"https://faxjiangyi.github.io/post/wei-shi-me-tcp-xu-yao-san-ci-wo-shou-si-ci-hui-shou/"},{"title":"IO中字节流和字符流","content":"字节流：流的内容是byte，常用InputStream和OutputStream操作 字符流：流的内容是string，常用Writer和Reader操作，部分方法要指定编码 带Buffered前缀的流操作类，具有缓冲作用，可以优化输入/输出性能 字节流和字符流都是阻塞的。 ","link":"https://faxjiangyi.github.io/post/io-zhong-zi-jie-liu-he-zi-fu-liu/"},{"title":"ElasticSearch与关系型数据库概念上区别","content":" 关系型数据库 ElasticSearch Database数据库 Index索引 Table表 Type类型（后续会被弃用） Row行 Document文档 Column列 Field域 Index索引 Everything is indexed一切都是索引的 ","link":"https://faxjiangyi.github.io/post/elasticsearch-yu-guan-xi-xing-shu-ju-ku-gai-nian-shang-qu-bie/"},{"title":"Thread.yield()方法","content":"暂停当前线程，资源由其他线程抢占。与wait方法区别是不需要唤醒，可以临时降低并发量。 ","link":"https://faxjiangyi.github.io/post/threadyieldfang-fa/"},{"title":"Thread.join()方法用途","content":"当A线程执行到B方法的join()方法时，A线程就会等待，直至B线程执行完或被结束。 ​ 可以用于临时加入线程执行。 // 例 public class JoinMain { public static void main(String[] args) { Runnable r1 = new Runable(){ // ... }; Runnable r2 = new Runable(){ // ... }; // 多线程启动 new Thread(r1).start(); // r1会加到main线程中来，待r1执行完或被结束，再往下执行 r1.join() new Thread(r2).start(); } } ","link":"https://faxjiangyi.github.io/post/threadjoinfang-fa-yong-tu/"},{"title":"wait()，notify(), notifyAll() 使用总结","content":" 可以使用wait和notify函数来实现线程间通信。可以用它们来实现多线程（&gt;3）之间的通信。 永远在synchronized的函数或对象里使用wait、notify和notifyAll，不然Java虚拟机会生成 IllegalMonitorStateException。 永远在while循环里而不是if语句下使用wait。这样，循环会在线程睡眠前后都检查wait的条件，并在条件实际上并未改变的情况下处理唤醒通知。 永远在多线程间共享的对象（在生产者消费者模型里即缓冲区队列）上使用wait。 基于前文提及的理由，更倾向用 notifyAll()，而不是 notify()。 ","link":"https://faxjiangyi.github.io/post/waitnotify-notifyall-shi-yong-zong-jie/"},{"title":"notify()和notifyAll()的区别","content":" notify()方法只会通知等待队列中的第一个相关线程 notifyAll()通知所有等待该竞争资源的线程 在经典生产者-消费者模型中，如果使用notify()，且配置多个消费者，可能会导致多个消费者循环调用，导致死锁；而使用notifyAll()，可以自加上状态控制wait()，唤醒所有线程，然后消费者会因为不符合状态控制而放弃权限，最终生产者抢占资源唤醒。 所以，当多个（两个以上的）线程操作同一个对象的时候最好使用的notifyAll()，这样就不会出现上述的问题了。 ","link":"https://faxjiangyi.github.io/post/notifyhe-notifyallde-qu-bie/"},{"title":"volatile关键字的意义","content":"对于多线程共享的变量，JVM的内存模型（JMM）会为不同的线程分配缓存，并在缓存中进行操作后，再写回到主内存中。 ​ 例：线程A和线程B都操作主线程中的一个变量X，JMM会在线程A和线程B上创建一个X的副本供操作，操作完成后再写回到主线程中。 ​ 会带来线程间数据不同步的问题。volatile关键字修饰的变量，将会强制各线程在主内存中进行操作，禁用高速缓存，以达到一致性。一致性相对锁而言较弱，但是效率高。 ​ 且编译器编译时，会对代码进行重排序优化，进而带来多线程安全问题。例： int a = 1; a = 2; a = 3; // 在编译器进行重排序优化后，上述语句会直接优化为： int a = 3; ​ volatile关键字修饰的变量，不允许优化。 ","link":"https://faxjiangyi.github.io/post/volatile-guan-jian-zi-de-yi-yi/"},{"title":"Thread.start和Thread.run的区别","content":"方法的定义 ​ start()方法在java.lang.Thread类中定义； ​ 而run()方法在java.lang.Runnable接口中定义，必须在实现类中重写。 新线程创建 ​ 当程序调用start()方法时，会创建一个新线程，然后执行run()方法，它是异步的。 ​ 如果我们直接调用run()方法，则不会创建新的线程，run()方法将作为当前调用线程本身的常规方法调用执行，并且不会发生多线程，是同步的。 多次调用 ​ 线程是有状态的，start()方法不能多次调用，否则抛出java.lang.IllegalStateException； ​ 而run()方法可以进行多次调用，因为它只是一种正常的方法调用。 ","link":"https://faxjiangyi.github.io/post/threadstart-he-threadrun-de-qu-bie/"},{"title":"线程池的拒绝策略","content":"简介 java里面的线程池引入了一个叫拒绝执行的策略模式，意思也就是说当池子满的时候该如何执行还在不断往里面添加的一些任务。 场景 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。 处理任务的优先级 ​ 核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 策略详情 ThreadPoolExecutor.DiscardPolicy()： 丢弃被拒绝的任务（不执行），底层的实现是直接调用空方法，什么都不做 ThreadPoolExecutor.AbortPolicy()： 抛出java.util.concurrent.RejectedExecutionException异常 ThreadPoolExecutor.DiscardOldestPolicy()： 丢弃队列中最老的任务 ThreadPoolExecutor.CallerRunsPolicy()： 直接在 execute 方法的调用线程中运行被拒绝的任务；如果调用者已关闭，则会丢弃该任务 ","link":"https://faxjiangyi.github.io/post/xian-cheng-chi-de-ju-jue-ce-lue/"},{"title":"Java常用线程池Executor","content":"什么是线程池 ​ 根据系统自身的环境情况，有效的限制执行线程的数量，使得运行效果达到最佳。线程主要是通过控制执行的线程的数量，超出数量的线程排队等候，等待有任务执行完毕，再从队列最前面取出任务执行。 线程池作用 减少创建和销毁线程的次数，每个工作线程可以多次使用 可根据系统情况调整执行的线程数量，防止消耗过多内存 常见线程池及使用 // 单个线程的线程池，即线程池中每次只有一个线程工作，单线程串行执行任务（队列） ExecutorService pool = Executors.newSingleThreadExecutor(); // 固定数量的线程池，每提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列直到前面的任务完成才继续执行 ExecutorService pool = Executors.newFixedThreadExecutor(5); // 可缓存线程池，当线程池大小超过了处理任务所需的线程，那么就会回收部分空闲（一般是60秒无执行）的线程，当有任务来时，又智能的添加新线程来执行 ExecutorService pool = Executors.newCacheThreadExecutor(); // 大小无限制的线程池，支持定时和周期性的执行线程 ExecutorService pool = Executors.newScheduleThreadExecutor(); Spring自定义线程池 ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); // 核心线程数 executor.setCorePoolSize(8); // 缓存队列 executor.setQueueCapacity(32); // 最大线程数 executor.setMaxPoolSize(32); // 溢出拒绝策略 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 线程名前缀 executor.setThreadNamePrefix(&quot;ThreadPool-&quot;); // 允许空闲时间 executor.setKeepAliveSeconds(30); ","link":"https://faxjiangyi.github.io/post/java-chang-yong-xian-cheng-chi-executor/"},{"title":"Map常见实现类","content":"HashMap, HashTable, ConcurrentHashMap, TreeMap, LinkedHashMap HashMap ​ 使用位桶（桶数组）+链表实现，线程不安全，默认桶位16，默认扩容因子0.75f ​ put时，计算key的hash值，放到相应余数的桶中。 ​ 如何处理hash冲突：桶位中存储的是链表，通过比对链表中Entry的key是否一致，一致覆盖，不一致加到链表的最低端。 ​ key和value允许null HashTable ​ 与HashMap相似，但是底层所有方法带synchronize关键字，线程安全，不允许null值key和value。jdk1.8后使用ConcorrentHashMap代替。 ConcorrentHashMap ​ 与HashMap相似，线程安全，但是使用的是分段锁而非synchronize，效率提高。 TreeMap ​ Key值会按ASCII编码排序，底层通过红黑树实现。 LinkedHashMap ​ Key值会按照put顺序排序，底层通过链表实现。 ","link":"https://faxjiangyi.github.io/post/map-chang-jian-shi-xian-lei/"},{"title":"TCP和UDP的区别","content":"TCP 优点 可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 缺点 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。 UDP 优点 快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。 缺点 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，那么： 什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 图解 TCP UDP 是否连接 面向连接 面向非连接 传输可靠性 可靠 不可靠 应用场合 少量数据 传输大量数据 速度 慢 快 总结 TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 TCP提供可靠的服务，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付 TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流；UDP是面向报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低 每一条TCP连接只能是点到点的；UDP支持一对一，一对多，多对一和多对多的交互通信 TCP首部开销20字节；UDP的首部开销只有8个字节 TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道 ","link":"https://faxjiangyi.github.io/post/tcp-he-udp-de-qu-bie/"},{"title":"CSRF攻击","content":"跨站请求伪造，缩写为：CSRF/XSRF 定义 ​ CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 危害 ​ 攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账等。造成的问题包括：个人隐私泄露以及财产安全。 例子 登录受信任网站A，并在本地生成Cookie； 在不登出A的情况下，访问危险网站B； 网站B中链接操作网站A中数据。 解决方法 以下所有方法的思路都是一样的：在客户端页面加入伪随机数。 方法一：Cookie Hashing。因为在黑客网站上无法获取到其他网站的Cookie（理论上），无法拿到正确的Hash，从而无法攻击。但是可能会通过XSS攻击泄露Cookie信息。一般攻击者看到要计算Hash，能劝退99%了。 方法二：加入一次性token。每个表单的提交都要请求不一样的token，服务器始终保存客户最后一次请求的token，则可以防止黑客提交其他表单。但是要确保服务器不会对卡片式浏览器产生影响。 方法三：验证码。对用户体验影响较大。 ","link":"https://faxjiangyi.github.io/post/csrf-gong-ji/"},{"title":"XSS攻击","content":"xss攻击的定义/危害/解决方法 定义 ​ 黑客在表单/链接中输入代码（一般是html或js），提交后保存到数据库或展示给其他人，与SQL注入类似，但是作用于前端。 危害 盗用Cookie，获取敏感信息； 利用iframe、frame、XMLHttpRequest方式，以（被攻击）用户的身份执行一些管理动作； 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作（CSRF）； 在访问量极大的一些页面上的XSS可以攻击一些小型网站，实现DDoS攻击。 解决方法 ​ 与SQL注入的解决方法类似，通过后端时将可疑字符过滤掉。 ","link":"https://faxjiangyi.github.io/post/xss-gong-ji/"},{"title":"GET和POST请求的区别","content":"语义上，使用上，本质上 1 语义上的区别 ​ 一般来说GET是获取数据，POST是提交数据的。但是因为GET和POST都是HTTP的方法，HTTP协议既然有了这两个方法，就是为了在特定的情况下区分应用。就有了我们所说的GET是获取数据，POST是提交数据的。 2 使用上的区别 GET参数通过URL传递，POST放在Request body中，GET参数直接暴露在URL上，所以不能用来传递敏感信息； GET请求只能进行url编码，而POST支持多种编码方式； 对参数的数据类型，GET只接受ASCII字符，而POST没有限制； GET请求在URL中传送的参数是有长度限制的，而POST没有（浏览器和服务器限制的）； GET是获取数据，所以GET请求是安全、幂等、是无害的，POST是向服务器传输数据，数据会被重新提交，POST回退时可能会对服务器产生影响； GET请求会被浏览器主动cache，而POST不会，除非手动设置； 3 产生数据包的区别 ​ GET产生一个TCP数据包；POST产生两个TCP数据包。 ​ 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； ​ 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据） ​ （并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次） 3 本质上的区别 ​ 本质上都是TCP链接，没有区别 ","link":"https://faxjiangyi.github.io/post/get-he-post-qing-qiu-de-qu-bie/"},{"title":"数据库事务","content":"什么是事务，事务的作用，事务带来的问题，事务的隔离级别 什么是事务 ​ 事务是访问数据库的一个操作序列，数据库应用系统通过事务集来完成对数据库的存取。事务的正确执行使得数据库从一种状态转换为另一种状态。事务必须服从的ACID原则，即： 1 原子性（Atomicity） ​ 即不可分割，事务要么全部被执行，要么全部不执行。如果事务的所有子事务全部提交成功，则所有的数据库操作被提交，数据库状态发生变化； 如果有子事务失败，则其他子事务的数据库操作被回滚，即数据库回到事务执行前的状态，不会发生状态转换。 2 一致性（Consistency） ​ 事务的执行使得数据库从一种正确状态转换成另外一种正确状态。 3 隔离性（Isolation） ​ 在事务正确提交之前，不允许把事务对该数据的改变提供给任何其他事务，即在事务正确提交之前，它可能的结果不应该显示给其他事务。 4 持久性（Durability） ​ 事务正确提交之后，其结果将永远保存在数据库之中，即使在事务提交之后有了其他故障，事务的处理结果也会得到保存。 备注 根据凤凰架构的说法：C是目的，AID是手段。 事务的作用 ​ 事务管理保证了用户的每一次操作都是可靠的，即便出现了异常的访问情况，也不至于破坏后台数据的完整性。 并发事务处理会带来的问题 1 更新丢失（Lost Update） ​ 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了由其他事务所作的更新。 ​ 一句话：事务A、B操作同一条数据，事务B提交覆盖了事务A 2 脏读（Dirty Reads） ​ 一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也就读取同一条记录，如果不加控制，第二个事务读取了这些”脏“数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做”脏读“ ​ 一句话：事务A提交了，事务B读到了提交前的数据 3 不可重复读（Non-Repeatable Reads） ​ 一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了，这种现象就叫做”不可重复读”。 ​ 一句话：在一个事务里面读取了两次某个数据，读出来的数据不一致（被其他事务更新/删除） 4 幻读（Phantom Reads） ​ 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象被称为”幻读”。 ​ 一句话：在一个事务里面读取了两次某批数据，读出来的数据不一致（被其他事务插入） 事务隔离级别 为了解决 丢失更新、脏读、不可重复读、幻读 问题，诞生了事务隔离。为什么要有事务隔离级别，事务隔离级别越高，在并发下会产生的问题就越少，但同时付出的性能消耗也将越大，因此很多时候必须在并发性和性能之间做一个权衡。 事务隔离级别有4种： READ_UNCOMMITTED 读未提交，即能够读取到没有被提交的数据，所以很明显这个级别的隔离机制无法解决脏读、不可重复读、幻读中的任何一种，因此很少使用。 READ_COMMITED ​ （Oracle默认级别） 读已提交，即能够读到那些已经提交的数据，自然能够防止脏读，但是无法限制不可重复读和幻读。 REPEATABLE_READ ​ （MySQL默认级别） 重复读取，即在数据读出来之后加锁，类似&quot;select * from XXX for update&quot;，明确数据读取出来就是为了更新用的，所以要加一把锁，防止别人修改它。REPEATABLE_READ的意思也类似，读取了一条数据，这个事务不结束，别的事务就不可以改这条记录，这样就解决了脏读、不可重复读的问题，但是幻读的问题还是无法解决。 SERLALIZABLE 串行化，最高的事务隔离级别，不管多少事务，挨个运行完一个事务的所有子事务之后才可以执行另外一个事务里面的所有子事务，这样就解决了脏读、不可重复读和幻读的问题了。但效率降低。 事务隔离级别解决问题图解 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ_UNCOMMITTED 是 是 是 否 RED_COMMITTED 否 是 是 否 REPEATABLE_READ 否 否 是 否 SERIALZABLE 否 否 否 是 ","link":"https://faxjiangyi.github.io/post/shi-wu/"},{"title":"TCP/IP五层模型对应的协议","content":"一般而言： 对于一台主机，它的操作系统内核实现了传输层到物理层的内容 对于一台路由器，它实现了从网络层到物理层 对于一台交换机，它实现了由数据链路层到物理层 对于集线器，他只实现了物理层。 ","link":"https://faxjiangyi.github.io/post/tcpip-wu-ceng-mo-xing-dui-ying-de-xie-yi/"},{"title":"二叉树的遍历方式","content":"1 广度优先遍历 ​ 又叫层次遍历，从上往下对每一层依次访问，在每一层中，从左往右（也可以从右往左）访问结点，访问进入下一层，直到没有结点可以访问为止。 ​ 一般通过队列实现 2 深度优先遍历 ​ 对每一个可能的分支路径深入到不能再深入为止，而且每个结点只能访问一次，可细分为以下三种遍历方式： 先序遍历：中左右 中序遍历：左中右**（常用）** 后序遍历：左右中 ​ 口诀：先中后，看&quot;中&quot;在哪里。 ​ 一般通过栈实现 ","link":"https://faxjiangyi.github.io/post/er-cha-shu-de-bian-li-fang-shi/"},{"title":"判断链表是否有环、求环长度","content":"​ 如 A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;B 方法1：判断两个指针走到某点步数是否一致 ​ 如指针1走到第二个B时用了5步，而从头遍历的指针2走到B时只用了2步，说明有环。 ​ 环长度 = step2 - step1 ​ 平均时间复杂度O(n²)，平均空间复杂度O(1) public static boolean circle() { // 两个指针指向头 Node p1 = head, p2 = head; // 双循环遍历节点 for (int step1 = 0; p1 != null; step1++) { p1 = p1.next; for (int step2 = 0; p2 != p1; step2++) { p2 = p2.next; } // 步数不一致，说明有环 if (step2 != step1) { return true; } p2 = head; } return false; } 方法2：Set去重 ​ 利用set的去重特性，HashSet入堆时 put(element) 方法会自判断是否已存在，若已存在，会返回false。 ​ 环长度自定义feild累加即可。 ​ 平均时间复杂度为O(n)，空间复杂度为O(n)。 方法3：快慢指针 ​ 快指针每次走2步，慢指针每次走1步。如果有环，慢指针必定会与快指针相遇。 ​ 环长度：相遇两次，第二次相遇时快指针走了2s步，慢指针走了1s步，环长度即为 2s - 1s =1s ​ 平均时间复杂度为O(n)，空间复杂度为O(1) public static boolean circle3() { // 从头开始 Node slow = head, fast = head; // 有终止节点，说明无环 while (fast != null &amp;&amp; fast.next != null) { // 分别前进1步、2步 slow = slow.next; fast = fast.next.next; // 慢指针追上快指针 if (slow == fast) { return true; } } return false; } ","link":"https://faxjiangyi.github.io/post/pan-duan-lian-biao-shi-fou-you-huan-qiu-huan-chang-du/"},{"title":"Kafka集群搭建配置","content":"本次演示使用 kafka_2.12-2.5.0 wsl2环境，单机集群 一、下载kafka http://kafka.apache.org/downloads.html 二、解压 tar -zxvf kafka_2.12-2.5.0.tgz 三、复制3份 cp -r kafka_2.12-2.5.0.tgz ./kafka-cluster/kafka1/ cp -r kafka_2.12-2.5.0.tgz ./kafka-cluster/kafka2/ cp -r kafka_2.12-2.5.0.tgz ./kafka-cluster/kafka3/ 四、新建3个kafka_data目录，用于存放kafka日志数据，不建议放在根目录中 注意：kafka-server每次启动前，要先清空掉日志文件 cd kafka-cluster mkdir data_kafka1 mkdir data_kafka2 mkdir data_kafka3 至此，文件目录如下 ├── data_kafka1 ├── data_kafka2 ├── data_kafka3 ├── kafka_1 ├── kafka_2 └── kafka_3 五、先启动zookeeper集群 看zookeeper集群部署文档，本次演示中，zk集群节点如下 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 六、设置各个kafka的server.properties文件信息 注意有坑 如果listeners配置的host是localhost或者127.0.0.1，在windows的linux子系统内部署的Kafka集群，windows中将无法访问到此集群 解决方法：将listener的host配置为linux机的局域网地址，或者host，后续用节点地址来访问kafka集群 1.在linux子系统中执行以下命令，拿到在局域网中本机地址，（即inet节点的172.23.112.173） ifconfig ############ eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.23.112.173 netmask 255.255.240.0 broadcast 172.23.127.255 inet6 fe80::215:5dff:fe73:d023 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:15:5d:73:d0:23 txqueuelen 1000 (Ethernet) RX packets 22748 bytes 34616063 (34.6 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3378 bytes 246784 (246.7 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 745864 bytes 146147115 (146.1 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 745864 bytes 146147115 (146.1 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 2.将此地址配置到server.properties的listeners中 文件配置 ./kafka1/config/server.properties # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the &quot;License&quot;); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # see kafka.server.KafkaConfig for additional details and defaults ########### Server Basics ########### # The id of the broker. This must be set to a unique integer for each broker. ## 注意修改此处，每个broker（分片）的id必须唯一 broker.id=1 ########### Socket Server Settings ########### # The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured. # FORMAT: # listeners = listener_name://host_name:port # EXAMPLE: # listeners = PLAINTEXT://your.host.name:9092 # listeners=PLAINTEXT://127.0.0.1:9092 ## 注意修改此处，每个broker须监听不同端口 listeners = PLAINTEXT://172.23.112.173:9092 # Hostname and port the broker will advertise to producers and consumers. If not set, # it uses the value for &quot;listeners&quot; if configured. Otherwise, it will use the value # returned from java.net.InetAddress.getCanonicalHostName(). # advertised.listeners=PLAINTEXT://127.0.0.1:9092 # Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details #listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL # The number of threads that the server uses for receiving requests from the network and sending responses to the network num.network.threads=3 # The number of threads that the server uses for processing requests, which may include disk I/O num.io.threads=8 # The send buffer (SO_SNDBUF) used by the socket server socket.send.buffer.bytes=102400 # The receive buffer (SO_RCVBUF) used by the socket server socket.receive.buffer.bytes=102400 # The maximum size of a request that the socket server will accept (protection against OOM) socket.request.max.bytes=104857600 ########### Log Basics ########### # A comma separated list of directories under which to store log files ## 注意修改此处，每个broker的日志地址须不一样 log.dirs=/home/jiangyi/env/kafka/kafka_cluster/data_kafka1/log # The default number of log partitions per topic. More partitions allow greater # parallelism for consumption, but this will also result in more files across # the brokers. num.partitions=1 # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown. # This value is recommended to be increased for installations with data dirs located in RAID array. num.recovery.threads.per.data.dir=1 ########### Internal Topic Settings ########### # The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot; # For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3. offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 ########### Log Flush Policy ########### # Messages are immediately written to the filesystem but by default we only fsync() to sync # the OS cache lazily. The following configurations control the flush of data to disk. # There are a few important trade-offs here: # 1. Durability: Unflushed data may be lost if you are not using replication. # 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush. # 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks. # The settings below allow one to configure the flush policy to flush data after a period of time or # every N messages (or both). This can be done globally and overridden on a per-topic basis. # The number of messages to accept before forcing a flush of data to disk #log.flush.interval.messages=10000 # The maximum amount of time a message can sit in a log before we force a flush #log.flush.interval.ms=1000 ########### Log Retention Policy ########### # The following configurations control the disposal of log segments. The policy can # be set to delete segments after a period of time, or after a given size has accumulated. # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens # from the end of the log. # The minimum age of a log file to be eligible for deletion due to age log.retention.hours=168 # A size-based retention policy for logs. Segments are pruned from the log unless the remaining # segments drop below log.retention.bytes. Functions independently of log.retention.hours. #log.retention.bytes=1073741824 # The maximum size of a log segment file. When this size is reached a new log segment will be created. log.segment.bytes=1073741824 # The interval at which log segments are checked to see if they can be deleted according # to the retention policies log.retention.check.interval.ms=300000 ########### Zookeeper ########### # Zookeeper connection string (see zookeeper docs for details). # This is a comma separated host:port pairs, each corresponding to a zk # server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;. # You can also append an optional chroot string to the urls to specify the # root directory for all kafka znodes. ## 注意修改此处，填入本地zk地址，多个逗号间隔 zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 # Timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=18000 ########### Group Coordinator Settings ########### # The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance. # The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms. # The default value for this is 3 seconds. # We override this to 0 here as it makes for a better out-of-the-box experience for development and testing. # However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup. group.initial.rebalance.delay.ms=0 ./kafka2/config/server.properties ## 与./kafka1/config/server.properties一致,只展示修改部分，省略...... ########### Server Basics ########### ## 注意修改此处，每个broker（分片）的id必须唯一 broker.id=2 ########### Socket Server Settings ########### ## 注意修改此处，每个broker须监听不同端口 listeners = PLAINTEXT://172.23.112.173:9093 ########### Log Basics ########### ## 注意修改此处，每个broker的日志地址须不一样 log.dirs=/home/jiangyi/env/kafka/kafka_cluster/data_kafka2/log ./kafka3/config/server.properties ## 与./kafka1/config/server.properties一致,只展示修改部分，省略...... ########### Server Basics ########### ## 注意修改此处，每个broker（分片）的id必须唯一 broker.id=3 ########### Socket Server Settings ########### ## 注意修改此处，每个broker须监听不同端口 listeners = PLAINTEXT://172.23.112.173:9094 ########### Log Basics ########### ## 注意修改此处，每个broker的日志地址须不一样 log.dirs=/home/jiangyi/env/kafka/kafka_cluster/data_kafka3/log 七、编写本地集群启动脚本 ./start-cluster.sh #!/bin/sh ## kafka启动前要删除所有本地日志 rm -rf /home/jiangyi/env/kafka/kafka_cluster/data_kafka*/* /home/jiangyi/env/kafka/kafka_cluster/kafka_1/bin/kafka-server-start.sh -daemon /home/jiangyi/env/kafka/kafka_cluster/kafka_1/config/server.properties echo &quot;kafka-cluster broker 1 started&quot; /home/jiangyi/env/kafka/kafka_cluster/kafka_2/bin/kafka-server-start.sh -daemon /home/jiangyi/env/kafka/kafka_cluster/kafka_2/config/server.properties echo &quot;kafka-cluster broker 2 started&quot; /home/jiangyi/env/kafka/kafka_cluster/kafka_3/bin/kafka-server-start.sh -daemon /home/jiangyi/env/kafka/kafka_cluster/kafka_3/config/server.properties echo &quot;kafka-cluster broker 3 started&quot; echo &quot;kafka-cluster started!!!&quot; 脚本设置为可运行 chmod a+x ./*.sh 至此，当前目录结构 ├── data_kafka1 ├── data_kafka2 ├── data_kafka3 ├── kafka_1 ├── kafka_2 ├── kafka_3 └── start-cluster.sh 八、运行启动脚本 启动 ./start-cluster.sh ## print kafka-cluster broker 1 started kafka-cluster broker 2 started kafka-cluster broker 3 started kafka-cluster started!!! 九、测试topic 创建test topic ./kafka_1/bin/kafka-topics.sh --create --zookeeper 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 --replication-factor 1 --partitions 1 --topic test 查看所有topic ./kafka_1/bin/kafka-topics.sh --list --zookeeper 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 十、测试producer和consumer producer（为测试集群，特意监听不同的端口） ./kafka_2/bin/kafka-console-producer.sh --bootstrap-server 172.23.112.173:9094 --topic test consumer ./kafka_3/bin/kafka-console-consumer.sh --bootstrap-server 172.23.112.173:9092 --topic test producer输入信息，consumer能收到即成功 ","link":"https://faxjiangyi.github.io/post/kafka-ji-qun-da-jian-pei-zhi/"},{"title":"Sentinel集成Nacos","content":"Sentinel集成Nacos 原理 nacos 作为配置中心（数据源），持久化存储规则 sentinel-client 从nacos配置中心动态同步限流规则 sentinel规则下发使用推模式 引入sentinel-datasource-nacos 实现AbstractDataSource 构造方法添加nacos配置监听器 sentinel-dashboard dashbaord的角色：只作为看板，实际规则以nacos为准 查询时，从nacos中取数据展示 提供可视化界面配置规则，crud到nacos Sentinel集成Nacos 操作 [ 参考文献 ] : https://xie.infoq.cn/article/3a7096dc3f2b98bb5a6b983ba 规则说明 [ 参考文献 ] : https://sentinelguard.io/zh-cn/docs/basic-api-resource-rule.html flow：流量控制 degrade：降级/熔断 param-flow：热点数据 热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效 authority：授权（白名单/黑名单） system：系统保护 gateway：网关规则 gw-flow：流量控制 gw-api-group：api分组 Nacos规则配置示例 基础配置 spring: cloud: sentinel: enabled: true ## 随应用启动加载 eager: true # feign集成sentinel feign: sentinel: enabled: true 环境关联配置-application spring: cloud: sentinel: ## dashboard传输地址 transport: dashboard: ${sentinel.dashboard.host}:${sentinel.dashboard.port} port: ${sentinel.port} datasource: flow: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-flow-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} # 规则类型，取值见： # org.springframework.cloud.alibaba.sentinel.datasource.RuleType rule-type: flow degrade: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-degrade-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: degrade system: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-system-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: system authority: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-authority-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: authority param-flow: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-param-flow-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: param-flow 环境关联配置-gateway spring: cloud: sentinel: ## dashboard传输地址 transport: dashboard: ${sentinel.dashboard.host}:${sentinel.dashboard.port} port: ${sentinel.port} ## 规则nacos数据源 datasource: ## 网关流控 gw-flow: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-gw-flow-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: GW_FLOW ## 网关路由分组 gw-api-group: nacos: server-addr: ${nacos地址} username: ${nacos账号} password: ${nacos密码} dataId: ${spring.application.name}-gw-api-group-rules groupId: SENTINEL_GROUP namespace: ${nacos命名空间} rule-type: GW_API_GROUP ## 其他规则... ","link":"https://faxjiangyi.github.io/post/sentinel-ji-cheng-nacos/"},{"title":"Zookeeper集群搭建配置","content":"单机集群测试 zk版本 3.4.6 一、下载zk https://www.apache.org/dyn/closer.lua/zookeeper/zookeeper-3.4.6/apache-zookeeper-3.4.6-bin.tar.gz 二、解压 tar -zxvf zookeeper-3.4.6.tar.gz 三、复制3份 cp -r zookeeper-3.4.6 ./zk-cluster/zk1/ cp -r zookeeper-3.4.6 ./zk-cluster/zk2/ cp -r zookeeper-3.4.6 ./zk-cluster/zk3/ 四、新建3个zk_data目录，用于存放zk数据，默认存放在zk根目录/data中，不建议放在zk根目录中 cd zk-cluster mkdir data_zk1 mkdir data_zk2 mkdir data_zk3 至此，文件目录如下 ├── data_zk1 ├── data_zk2 ├── data_zk3 ├── zk1 ├── zk2 └── zk3 五、在各个zk_data目录下，新建名为&quot;myid&quot;的文件，里面放置zk节点命名的id echo 1 &gt; zk1/myid echo 2 &gt; zk2/myid echo 3 &gt; zk3/myid 至此，文件目录如下 ├── data_zk1 │ └── myid ├── data_zk2 │ └── myid ├── data_zk3 │ └── myid ├── zk1 ├── zk2 └── zk3 六、设置各个zk中的配置文件信息 ./zk1/conf/zoo.cfg # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. ## 注意，这里配置每个zk的data文件夹路径 dataDir=/home/jiangyi/env/zookeeper/zk-cluster/data_zk1 # the port at which the clients will connect ## 注意，这里每个zk的配置文件端口不能一样 clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to &quot;0&quot; to disable auto purge feature #autopurge.purgeInterval=1 ## Metrics Providers # # https://prometheus.io Metrics Exporter #metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider #metricsProvider.httpPort=7000 #metricsProvider.exportJvmInfo=true ## 注意，server.*对应的是每个zkdata中的myid server.1=127.0.0.1:2888:3888 server.2=127.0.0.1:2889:3889 server.3=127.0.0.1:2890:3890 ./zk2/conf/zoo.cfg ## 与zk1/conf/zoo.cfg一致,只展示修改部分，省略...... ## 注意，这里配置每个zk的data文件夹路径 dataDir=/home/jiangyi/env/zookeeper/zk-cluster/data_zk2 # the port at which the clients will connect ## 注意，这里每个zk的配置文件端口不能一样 clientPort=2182 ./zk3/conf/zoo.cfg ## 与zk1/conf/zoo.cfg一致,只展示修改部分，省略...... ## 注意，这里配置每个zk的data文件夹路径 dataDir=/home/jiangyi/env/zookeeper/zk-cluster/data_zk3 # the port at which the clients will connect ## 注意，这里每个zk的配置文件端口不能一样 clientPort=2183 七、编写本地集群启动脚本 ./start-cluster.sh #!/bin/sh ./zk1/bin/zkServer.sh start ./zk2/bin/zkServer.sh start ./zk3/bin/zkServer.sh start echo &quot;zk-server-local-cluster started!&quot; ./stop-cluster.sh #!/bin/sh ./zk1/bin/zkServer.sh stop ./zk2/bin/zkServer.sh stop ./zk3/bin/zkServer.sh stop echo &quot;zk-server-local-cluster stopped!&quot; ./show-cluster-status.sh #!/bin/sh ./zk1/bin/zkServer.sh status ./zk2/bin/zkServer.sh status ./zk3/bin/zkServer.sh status 脚本设置为可运行 chmod 777 ./*.sh 至此，当前目录结构 ├── show-cluster-status.sh ├── start-cluster.sh ├── stop-cluster.sh ├── data_zk1 │ └── myid ├── data_zk2 │ └── myid ├── data_zk3 │ └── myid ├── zk1 ├── zk2 └── zk3 八、运行启动脚本 启动 ./start-cluster.sh 查看状态，出现leader及follower即成功 ./show-cluster-status.sh #### /usr/bin/java ZooKeeper JMX enabled by default Using config: /home/jiangyi/env/zookeeper/zk-cluster/zk1/bin/../conf/zoo.cfg Client port found: 2181. Client address: localhost. Client SSL: false. Mode: follower /usr/bin/java ZooKeeper JMX enabled by default Using config: /home/jiangyi/env/zookeeper/zk-cluster/zk2/bin/../conf/zoo.cfg Client port found: 2182. Client address: localhost. Client SSL: false. Mode: leader /usr/bin/java ZooKeeper JMX enabled by default Using config: /home/jiangyi/env/zookeeper/zk-cluster/zk3/bin/../conf/zoo.cfg Client port found: 2183. Client address: localhost. Client SSL: false. Mode: follower ","link":"https://faxjiangyi.github.io/post/zookeeper-ji-qun-da-jian-pei-zhi/"},{"title":"Hello World!","content":"程序员的创世宣言。 搞了一天了，搭建一个博客，感觉还不错。 希望一天比一天好。 既然是创世，那就将本文章创建时间改成同出生日期吧。 ","link":"https://faxjiangyi.github.io/post/helloworld/"}]}